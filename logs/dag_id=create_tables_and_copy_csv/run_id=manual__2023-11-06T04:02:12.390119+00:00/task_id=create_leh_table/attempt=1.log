[2023-11-06T04:02:14.736+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: create_tables_and_copy_csv.create_leh_table manual__2023-11-06T04:02:12.390119+00:00 [queued]>
[2023-11-06T04:02:14.747+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: create_tables_and_copy_csv.create_leh_table manual__2023-11-06T04:02:12.390119+00:00 [queued]>
[2023-11-06T04:02:14.748+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-11-06T04:02:14.768+0000] {taskinstance.py:1327} INFO - Executing <Task(SnowflakeOperator): create_leh_table> on 2023-11-06 04:02:12.390119+00:00
[2023-11-06T04:02:14.774+0000] {standard_task_runner.py:57} INFO - Started process 668 to run task
[2023-11-06T04:02:14.779+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'create_tables_and_copy_csv', 'create_leh_table', 'manual__2023-11-06T04:02:12.390119+00:00', '--job-id', '70', '--raw', '--subdir', 'DAGS_FOLDER/copy_processed_data_to_snowflake.py', '--cfg-path', '/tmp/tmpj4zgb7ry']
[2023-11-06T04:02:14.782+0000] {standard_task_runner.py:85} INFO - Job 70: Subtask create_leh_table
[2023-11-06T04:02:14.846+0000] {task_command.py:410} INFO - Running <TaskInstance: create_tables_and_copy_csv.create_leh_table manual__2023-11-06T04:02:12.390119+00:00 [running]> on host 0ca024afdc5f
[2023-11-06T04:02:14.957+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='create_tables_and_copy_csv' AIRFLOW_CTX_TASK_ID='create_leh_table' AIRFLOW_CTX_EXECUTION_DATE='2023-11-06T04:02:12.390119+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-11-06T04:02:12.390119+00:00'
[2023-11-06T04:02:14.959+0000] {sql.py:265} INFO - Executing: 
        select * from IDENTIFIER('"PS_STAGING_DB"."PS_STAGING_SCHEMA"."PURCHASES"') limit 100
    
[2023-11-06T04:02:14.973+0000] {base.py:73} INFO - Using connection ID 'snowflake_default' for task execution.
[2023-11-06T04:02:15.035+0000] {providers_manager.py:593} WARNING - The connection type 'aws' is already registered in the package 'apache-***-providers-amazon' with different class names: '***.providers.amazon.aws.hooks.base_aws.AwsBaseHook' and '***.providers.amazon.aws.hooks.redshift.RedshiftDataHook'. 
[2023-11-06T04:02:15.303+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/snowflake/connector/options.py:109: UserWarning: You have an incompatible version of 'pyarrow' installed (6.0.1), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
  "pyarrow", installed_pyarrow_version, pandas_pyarrow_extra

[2023-11-06T04:02:15.429+0000] {base.py:73} INFO - Using connection ID 'snowflake_default' for task execution.
[2023-11-06T04:02:15.441+0000] {connection.py:300} INFO - Snowflake Connector for Python Version: 3.0.4, Python Version: 3.7.13, Platform: Linux-6.4.16-linuxkit-x86_64-with-debian-11.4
[2023-11-06T04:02:15.442+0000] {connection.py:1013} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-11-06T04:02:15.443+0000] {connection.py:1030} INFO - Setting use_openssl_only mode to False
[2023-11-06T04:02:16.766+0000] {cursor.py:806} INFO - query: [ALTER SESSION SET autocommit=False]
[2023-11-06T04:02:16.906+0000] {cursor.py:819} INFO - query execution done
[2023-11-06T04:02:16.906+0000] {cursor.py:962} INFO - Number of results in first chunk: 1
[2023-11-06T04:02:16.908+0000] {sql.py:375} INFO - Running statement: select * from IDENTIFIER('"PS_STAGING_DB"."PS_STAGING_SCHEMA"."PURCHASES"') limit 100, parameters: None
[2023-11-06T04:02:16.908+0000] {cursor.py:806} INFO - query: [select * from IDENTIFIER('"PS_STAGING_DB"."PS_STAGING_SCHEMA"."PURCHASES"') limi...]
[2023-11-06T04:02:17.223+0000] {cursor.py:819} INFO - query execution done
[2023-11-06T04:02:17.224+0000] {cursor.py:962} INFO - Number of results in first chunk: 40
[2023-11-06T04:02:17.225+0000] {sql.py:384} INFO - Rows affected: 40
[2023-11-06T04:02:17.227+0000] {snowflake.py:391} INFO - Rows affected: 40
[2023-11-06T04:02:17.227+0000] {snowflake.py:392} INFO - Snowflake query id: 01b023d2-0004-d155-0000-0001ead7332d
[2023-11-06T04:02:17.228+0000] {cursor.py:806} INFO - query: [COMMIT]
[2023-11-06T04:02:17.360+0000] {cursor.py:819} INFO - query execution done
[2023-11-06T04:02:17.361+0000] {cursor.py:962} INFO - Number of results in first chunk: 1
[2023-11-06T04:02:17.361+0000] {connection.py:605} INFO - closed
[2023-11-06T04:02:17.465+0000] {connection.py:608} INFO - No async queries seem to be running, deleting session
[2023-11-06T04:02:17.618+0000] {taskinstance.py:1350} INFO - Marking task as SUCCESS. dag_id=create_tables_and_copy_csv, task_id=create_leh_table, execution_date=20231106T040212, start_date=20231106T040214, end_date=20231106T040217
[2023-11-06T04:02:17.656+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-11-06T04:02:17.683+0000] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
